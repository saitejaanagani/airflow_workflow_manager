from airflow import DAG
from airflow.operators.dummy import DummyOperator
from datetime import datetime

default_args = {
    'owner': '{{ owner }}',
    'depends_on_past': False,
}

with DAG(
    dag_id='{{ dag_id }}',
    default_args=default_args,
    description='S3 to Redshift loader DAG',
    schedule_interval='{{ schedule_interval }}',
    start_date=datetime.strptime('{{ start_date }}', '%Y-%m-%d'),
    catchup=False,
    tags=['s3', 'redshift']
) as dag:

    start = DummyOperator(task_id='start')
    load = DummyOperator(task_id='load_data_to_redshift')
    end = DummyOperator(task_id='end')

    start >> load >> end